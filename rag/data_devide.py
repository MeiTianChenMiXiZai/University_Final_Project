# -*- coding: utf-8 -*-
import os
import json
import re
from tqdm import tqdm
from timeit import default_timer as timer
from io import BytesIO
from docx import Document
import pandas as pd
from data.parser import PdfParser, ExcelParser
from docx2pdf import convert
import os
from pathlib import Path


# åŸå§‹æ”¿ç­–æ–‡ä»¶ç›®å½•
POLICY_DIR = os.path.join(os.path.dirname(__file__), "..", "data", "policy")
# è§£æåçš„æ•°æ®å­˜å‚¨è·¯å¾„
OUTPUT_FILE = os.path.join(os.path.dirname(__file__), "..", "rag", "res", "processed_policies.json")

UPLOAD_DIR = Path(__file__).resolve().parent.parent / "data" / "policy"

# ç¡®ä¿å­˜å‚¨ç›®å½•å­˜åœ¨
os.makedirs(os.path.dirname(OUTPUT_FILE), exist_ok=True)


class Pdf(PdfParser):
    def __call__(self, filename, binary=None, from_page=0, to_page=100000, zoomin=3, callback=None):
        self.pdf_path = filename
        start = timer()
        if callback:
            callback(msg="OCR is running...")

        self.__images__(filename if not binary else binary, zoomin, from_page, to_page, callback)
        if callback:
            callback(msg="OCR finished")

        self._layouts_rec(zoomin)  # ç‰ˆé¢åˆ†æ
        self._table_transformer_job(zoomin)  # è¡¨æ ¼è½¬æ¢
        self._text_merge()  # æ–‡æœ¬åˆå¹¶
        tbls = self._extract_table_figure(True, zoomin, True, True)  # æå–è¡¨æ ¼ & å›¾åƒ

        text_with_positions = []
        for b in self.boxes:
            text = b.get("text", "").strip()

            # **ğŸ“Œ ä¿®æ­£ `page` è¯»å–æ–¹å¼**
            page = b.get("page", b.get("page_number", -1))

            # **ğŸ“Œ ä¿®æ­£ `y0, y1` è¯»å–æ–¹å¼**
            x0 = b.get("x0", 0.0)
            y0 = b.get("y0", b.get("top", 0.0))
            x1 = b.get("x1", 0.0)
            y1 = b.get("y1", b.get("bottom", 0.0))


            pos_info = f"@@{page}\t{x0:.1f}\t{y0:.1f}\t{x1:.1f}\t{y1:.1f}##"
            text_with_positions.append(text + pos_info)

        return "\n".join(text_with_positions), tbls



# ========== ğŸ“Œ Excel è§£æ==========
class Excel(ExcelParser):
    def __call__(self, filename, binary=None):
        df = pd.read_excel(filename if not binary else BytesIO(binary), sheet_name=None)
        tables = []

        for sheet_name, sheet in df.items():
            html = f"<h3>{sheet_name}</h3><table border='1'>"
            html += sheet.to_html(index=False, escape=False)
            html += "</table>"
            tables.append(html)

        return [], tables


# ========== ğŸ“Œ æ–‡æœ¬åˆ‡åˆ†ï¼ˆæå‡ RAG æ£€ç´¢èƒ½åŠ›ï¼‰ ==========
def chunk_text(text, chunk_size=128):
    """å°†æ–‡æœ¬åˆ‡åˆ†ä¸ºå°æ®µï¼Œæé«˜ RAG æ£€ç´¢èƒ½åŠ›"""
    delimiters = re.compile(r"[!?ã€‚ï¼›ï¼ï¼Ÿ]")
    sections = delimiters.split(text)
    chunks = []
    buffer = ""

    for sec in sections:
        if len(buffer) + len(sec) < chunk_size:
            buffer += sec
        else:
            chunks.append(buffer)
            buffer = sec
    if buffer:
        chunks.append(buffer)

    return chunks


def process_policy_file(file_path):
    """æ ¹æ®æ–‡ä»¶ç±»å‹é€‰æ‹©åˆé€‚çš„è§£æå™¨"""
    ext = os.path.splitext(file_path)[1].lower()

    if ext not in [".pdf", ".xlsx"]:
        print(f"âŒ è·³è¿‡ä¸æ”¯æŒçš„æ–‡ä»¶: {file_path}")
        return None

    parser = {"pdf": Pdf(), "xlsx": ExcelParser()}.get(ext[1:])

    try:
        if ext == ".xlsx":
            parsed_result = parser(file_path)

            print(f"ğŸ“Œ DEBUG: `ExcelParser` è§£æè¿”å› -> {type(parsed_result)}, å€¼: {parsed_result}")

            if isinstance(parsed_result, tuple) and len(parsed_result) == 2:
                text_content, tables = parsed_result
            elif isinstance(parsed_result, list):
                text_content = ""
                tables = parsed_result
            elif isinstance(parsed_result, pd.DataFrame):
                text_content = ""
                tables = [parsed_result.to_html(index=False, escape=False)]
            else:
                print(f"âš ï¸ `ExcelParser` è¿”å›æœªçŸ¥æ ¼å¼: {type(parsed_result)}ï¼Œè¯·æ£€æŸ¥ `ExcelParser` ä»£ç ã€‚")
                return None
        else:
            text_content, tables = parser(file_path)

        print(f"ğŸ” DEBUG: {file_path} è§£æè¿”å›ï¼š{type(text_content)}, {type(tables)}")

        if text_content is None:
            print(f"âš ï¸ `PdfParser` è§£æå¤±è´¥ï¼Œæœªè¿”å›æœ‰æ•ˆæ–‡æœ¬: {file_path}")
            return None

        if isinstance(text_content, str):
            # âœ… `Pdf` è§£æååº”è¯¥æ˜¯ `str` æ ¼å¼çš„æ–‡æœ¬
            text_lines = text_content.strip().split("\n")
        elif isinstance(text_content, list):
            # âœ… `Docx` è§£æå™¨å¯èƒ½è¿”å› `list`
            text_lines = [t[0] if isinstance(t, tuple) else str(t) for t in text_content]
        else:
            print(f"âš ï¸ `text_content` è§£ææ ¼å¼æœªçŸ¥: {type(text_content)}")
            text_lines = []

        # âœ… ç¡®ä¿ `tables` ä¸æ˜¯ `None`
        if not tables:
            tables = []

        # âœ… ä¿æŒ `text_chunks` é‡Œå¸¦æœ‰ä½ç½®ä¿¡æ¯
        return {
            "file_name": os.path.basename(file_path),
            "text_chunks": chunk_text("\n".join(text_lines)),  # âœ… è¿™é‡Œä¸ä¼šä¸¢å¤±ä½ç½®ä¿¡æ¯
            "tables": tables
        }

    except Exception as e:
        import traceback
        error_message = traceback.format_exc()
        print(f"âš ï¸ è§£æå¤±è´¥: {file_path}, é”™è¯¯è¯¦æƒ…:\n{error_message}")
        return None




def convert_all_docx_to_pdf():
    """å°† UPLOAD_DIR ä¸­æ‰€æœ‰ docx æ–‡ä»¶è½¬æ¢ä¸º PDF"""
    docx_files = [f for f in os.listdir(UPLOAD_DIR) if f.endswith(".docx")]

    if not docx_files:
        print("âœ… æ²¡æœ‰éœ€è¦è½¬æ¢çš„ Word æ–‡ä»¶ã€‚")
        return

    for docx_file in docx_files:
        docx_path = str(UPLOAD_DIR / docx_file)
        try:
            print(f"ğŸ”„ æ­£åœ¨è½¬æ¢: {docx_file}")
            convert(docx_path)
            print(f"âœ… è½¬æ¢å®Œæˆ: {docx_file}")
        except Exception as e:
            print(f"âŒ è½¬æ¢å¤±è´¥: {docx_file}, é”™è¯¯: {e}")




# ========== ğŸ“Œ å¤„ç†æ‰€æœ‰æ”¿ç­–æ–‡ä»¶ ==========

def process_policy_files():
    """ğŸ”„ å…ˆè½¬æ¢ `.docx`ï¼Œå†éå† `.pdf` å’Œ `.xlsx` è§£æ"""
    print("ğŸ“‚ æ­£åœ¨åŠ è½½æ”¿ç­–æ–‡ä»¶...")

    convert_all_docx_to_pdf()  # âœ… **å…ˆè½¬æ¢ Word**

    existing_data = load_existing_data()
    new_data = {}

    # **éå†ç›®å½•ï¼Œè§£æ `.pdf` å’Œ `.xlsx`**
    for root, _, files in os.walk(POLICY_DIR):
        for file in tqdm(files, desc="è§£ææ”¿ç­–æ–‡ä»¶"):
            file_path = os.path.join(root, file)

            # âœ… **åªå¤„ç† `.pdf` å’Œ `.xlsx`**
            if not file.endswith((".pdf", ".xlsx")):
                continue

            if file in existing_data:  # âœ… **é¿å…é‡å¤è§£æ**
                print(f"â© è·³è¿‡å·²è§£ææ–‡ä»¶: {file}")
                continue

            print(f"ğŸ” è§£ææ”¿ç­–æ–‡ä»¶: {file}")
            parsed_data = process_policy_file(file_path)

            if parsed_data:
                new_data[file] = parsed_data
                print(f"âœ… è§£ææˆåŠŸ: {file}")
            else:
                print(f"âŒ è§£æå¤±è´¥: {file}")

    if new_data:
        existing_data.update(new_data)
        save_json(existing_data)
        print(f"âœ… è§£æå®Œæˆï¼å…±æ–°å¢ {len(new_data)} æ¡æ”¿ç­–æ•°æ®ã€‚")
    else:
        print("âœ… æ²¡æœ‰æ–°æ–‡ä»¶éœ€è¦è§£æï¼Œæ‰€æœ‰æ”¿ç­–æ•°æ®å·²æ˜¯æœ€æ–°ï¼")


# ========== ğŸ“Œ åŠ è½½ & å­˜å‚¨ JSON ==========
def load_existing_data():
    """åŠ è½½å·²è§£æçš„ JSON æ•°æ®ï¼Œé¿å…é‡å¤å¤„ç†"""
    if os.path.exists(OUTPUT_FILE):
        try:
            with open(OUTPUT_FILE, "r", encoding="utf-8") as f:
                return json.load(f)
        except json.JSONDecodeError:
            return {}
    return {}


def save_json(data):
    """å­˜å‚¨ JSON æ•°æ®"""
    with open(OUTPUT_FILE, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=4)


# ========== ğŸ“Œ ä¸»è¿è¡Œå…¥å£ ==========
if __name__ == "__main__":
    process_policy_files()
